# -*- coding: utf-8 -*-
"""ProyectoMiocardio_def.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PjrhFuGv2s8PEBzmSPQ04KDLzyY4oqDg

# Import para la maquina con Google Drive
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use("ggplot")
# %matplotlib inline

import tensorflow as tf

print(os.getcwd())
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

"""# Cargar y preprocesar datos

"""

# OPCION 1: Subir archivos al google drive, preferentemente subir la totalidad
# la carpeta a la caprte del drive raiz. Si no, modificar a la dirección escrita

from google.colab import drive
drive.mount('/content/drive')

option = 1

if option == 1:
  # OPCION 1: Subir archivos al google drive, preferentemente subir la totalidad
  # la carpeta a la caprte del drive raiz. Si no, modificar a la dirección escrita
  train_imgs = np.load('./drive/MyDrive/MIOCARDIO/train_imgs.npy')
  train_annot = np.load('./drive/MyDrive/MIOCARDIO/train_annot.npy')
  test_imgs = np.load('./drive/MyDrive/MIOCARDIO/test_imgs.npy')
  test_annot = np.load('./drive/MyDrive/MIOCARDIO/test_annot.npy')
  val_imgs = np.load('./drive/MyDrive/MIOCARDIO/val_imgs.npy')
  val_annot = np.load('./drive/MyDrive/MIOCARDIO/val_annot.npy')

else:
  # OPCION 2: Subir archivos al google colab, preferentemente subir la totalidad
  # la carpeta a la caprte del drive raiz. Si no, modificar a la dirección escrita
  train_imgs = np.load('./MIOCARDIO/train_imgs.npy')
  train_annot = np.load('./MIOCARDIO/train_annot.npy')
  test_imgs = np.load('./MIOCARDIO/test_imgs.npy')
  test_annot = np.load('./MIOCARDIO/test_annot.npy')
  val_imgs = np.load('./MIOCARDIO/val_imgs.npy')
  val_annot = np.load('./MIOCARDIO/val_annot.npy')

# Cambia el tipo de las imagenes a float
train_imgs = train_imgs.astype('float32')
train_annot = train_annot.astype('float32')
test_imgs = test_imgs.astype('float32')
test_annot = test_annot.astype('float32')
val_imgs = val_imgs.astype('float32')
val_annot = val_annot.astype('float32')

# Cambiamos los pixeles asociado a la clase 2 a que sean de clase 0
train_annot = np.where(train_annot[:][:][:]==2, 0, train_annot)
test_annot = np.where(test_annot[:][:][:]==2, 0, test_annot)
val_annot = np.where(val_annot[:][:][:]==2, 0, val_annot)

train_imgs = train_imgs / 255
test_imgs = test_imgs / 255
val_imgs = val_imgs / 255

train_imgs = tf.constant(np.expand_dims(train_imgs, axis=3))
train_annot = tf.constant(np.expand_dims(train_annot, axis=3))
test_imgs = tf.constant( np.expand_dims(test_imgs, axis=3))
test_annot = tf.constant(np.expand_dims(test_annot, axis=3))
val_imgs = tf.constant(np.expand_dims(val_imgs, axis=3))
val_annot = tf.constant(np.expand_dims(val_annot, axis=3))

print(train_imgs.shape)
print(val_imgs.shape)
print(test_imgs.shape)

"""# Plots para mostrar los datos y el sector esperado

"""

def display(display_list):
  '''
  Plotea graficos de la base de datos, mostrando la imagen de input con la 
  imagen que se espera conseguir.

  input : Un listado de matrices de 256x256

  '''
  plt.figure(figsize=(15, 15))
  title = ['Input Image', 'True Mask', 'Predicted Mask']

  for i in range(len(display_list)):
    plt.subplot(1, len(display_list), i+1)
    plt.title(title[i])
    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))
  plt.show()

for i in range(10):
  num = np.random.randint(len(train_imgs)-10)
  display([train_imgs[num], train_annot[num]])

"""# Creación del modelo

"""

def conv2d_block(input_tensor, n_filters, kernel_size = 3):
    """Funcion que retorna dos capas convolusionales continuas
      params:
      - input_tensor: capa inicial a unir
      - n_filters: numero de filtros a usar
      - kernerl_size: tamaño del kernel a usar

      return:
      - x: objeto de layers que representa la capa final del bloque de las dos 
        capas convolucionales
    """
    # first layer
    x = tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same', activation="relu")(input_tensor)
    
    # second layer
    x = tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same', activation="relu")(x)
    
    return x

def get_unet(input_img, n_filters = 16, dropout = 0.1):
    """Funcnion para crear la Unet
    
      params:
      - input_images = tupla de 3 dimensiones con las dimensiones de la matriz
        entrada
      - n_filtros = numero de filtros iniciales
      - dropout = indice de dropout

      Return:
      - modelo: Un objeto Model de tensorflow con el modelo Unet creado
    """
    # Contracting Path
    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3)
    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)
    if dropout > 0:
      p1 = tf.keras.layers.Dropout(dropout)(p1)
    
    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3)
    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)
    if dropout > 0:
      p2 = tf.keras.layers.Dropout(dropout)(p2)
    
    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3)
    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)
    if dropout > 0:
      p3 = tf.keras.layers.Dropout(dropout)(p3)
    
    c4 = conv2d_block(p3, n_filters = n_filters * 8, kernel_size = 3)
    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)
    if dropout > 0:
      p4 = tf.keras.layers.Dropout(dropout)(p4)
    
    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3)
    
    # Expansive Path
    u6 = tf.keras.layers.Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = "same")(c5)
    u6 = tf.keras.layers.concatenate([u6, c4])
    if dropout > 0:
      u6 = tf.keras.layers.Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3)
    
    u7 = tf.keras.layers.Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)
    u7 = tf.keras.layers.concatenate([u7, c3])
    if dropout > 0:
      u7 = tf.keras.layers.Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3)
    
    u8 = tf.keras.layers.Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)
    u8 = tf.keras.layers.concatenate([u8, c2])
    if dropout > 0:
      u8 = tf.keras.layers.Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3)
    
    u9 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)
    u9 = tf.keras.layers.concatenate([u9, c1])
    if dropout > 0:
      u9 = tf.keras.layers.Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3)
    
    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)
    model = tf.keras.Model(inputs=[input_img], outputs=[outputs])
    return model
  
# Creación de metricas
metrics=["accuracy",  tf.keras.metrics.MeanIoU(2), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]

# Creación del modelo
inputs = tf.keras.layers.Input((256, 256, 1), name='imagen')
model = get_unet(inputs, n_filters=16, dropout=0.2)
model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy(), metrics=metrics)

# Callbacks
log_dir = "logs/fit2/"
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
train_plot = np.random.randint(len(train_imgs)-10)
def plot_callback(i):
  display([train_imgs[i], train_annot[i], model.predict(train_imgs[i:(i+1)])[0]])

class PlotCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs=None):
    plot_callback(train_plot)
    print ('\nSample Prediction after epoch {}\n'.format(epoch+1))

callbacks = [
    tensorboard_callback,
    PlotCallback()
]

"""# Información del modelo"""

model.summary()
tf.keras.utils.plot_model(model, show_shapes=True)

"""# Segmento de Entrenamiento"""

predict = model.predict(test_imgs[10:11])
for i in range(1):
  display([test_imgs[10], test_annot[10], predict[i]])

results = model.fit(train_imgs, train_annot, batch_size=32, epochs=15,\
                    validation_data=(test_imgs, test_annot), callbacks = callbacks)

"""# Segmento de validación y predicción"""

predict = model.predict(test_imgs)

for i in range(20):
  num = np.random.randint(len(test_imgs)-20)
  display([test_imgs[i], test_annot[i], predict[i]])

"""# Gráficos de metricas"""

plt.figure(figsize=(10, 10))
plt.title("Learning curve")
plt.plot(results.history["loss"], label="loss")
plt.plot(results.history["val_loss"], label="val_loss")
plt.xlabel("Epochs")
plt.ylabel("log_loss")
plt.legend();

plt.figure(figsize=(10, 10))
plt.title("Accuracy curve")
plt.plot(results.history["accuracy"], label="accuracy")
plt.plot(results.history["val_accuracy"], label="val_accuracy")
plt.xlabel("Epochs")
plt.ylabel("log_accuracy")
plt.legend();

# F1-score (DICE)
presicion = results.history["precision"]
presicion_val = results.history["val_precision"]
recall = results.history["recall"]
recall_val = results.history["val_recall"]

dice = (np.multiply(presicion, recall)*2)/(np.add(presicion, recall))
dice_val = (np.multiply(presicion_val, recall_val)*2)/(np.add(presicion_val, recall_val))

plt.figure(figsize=(10, 10))
plt.title("F1 curve")
plt.plot(dice, label="f1")
plt.plot(dice_val , label="val_f1")
plt.xlabel("Epochs")
plt.ylabel("log_f1")
plt.legend();

plt.figure(figsize=(10, 10))
plt.title("IoU curve")
plt.plot(results.history["mean_io_u"], label="iou")
plt.plot(results.history["val_mean_io_u"] , label="val_iou")
plt.xlabel("Epochs")
plt.ylabel("log_f1")
plt.legend();

"""# Tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %reload_ext tensorboard
# %tensorboard --logdir logs/fit2/